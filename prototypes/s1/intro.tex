\documentclass[twoside]{report}

\newcommand{\tuple}[1]{$(#1)$}

\usepackage{alltt}

\begin{document}
\title{The StreamPy language}
\author{Lu\'{\i}s Pureza}

\maketitle

\chapter{Introduction}
Any new programming language such as StreamPy must be designed with a set of principles in mind. Some of these are quite general --- ``Be useful!'', while others are choosen carefully by the designers to set the new language apart from any other, like Python's ``There should be one --- and preferably only one --- obvious way to do it.''. These principles become a major influence in the resulting language and even define what developers sometimes call the philosophy of the language. It is important that the language adheres to these principles. Otherwise, it just won't make sense.

These are the principles that drove the design of the StreamPy language:

\begin{description}
\item[Be powerful] The set of operations allowed in a query should be large enough to accommodate most things users might want to do with their data. Frequent operations should be simple and rare operations should be possible. But let's be pragmatic: StreamPy does not intend to be the holy grail of data analysis. More complicated processing can always be delegated to a different application (Matlab comes to mind);
\item[Be expressive] StreamPy queries should be straightforward to read, write and understand by the developer. In particular, it should be possible to partition big queries into smaller ones in a step-by-step fashion --- like a procedural programming language, where each statement specifies a new operation acting on the result of the previous statement. Also, common operations should be expressible directly by what they mean and not as an opaque set of SQL-like constructs that hide their real meaning;
\item[Be coherent] In Smalltalk, everything is an object and even the addition of two numbers is seen as messages flowing between them. Lisp programs are just data and any Lisp fan will happily explain why that has so many advantages. Java, on the other hand, distinguishes between built-in types like integers and user-defined types and this distinction frequently bothers developers. Coherency makes the language easier to understand because you have less rules and exceptions. But it's far more than that: a coherent language shows how well-thought it was. This kind of elegance cannot be ignored.
\end{description}

By the end of this document, StreamPy should just make sense. Every feature or construct should have a well-defined purpose and be generally applicable to a wide-range of problems. This is a major goal. If it's not accomplished, then yours truly has failed.

Also, please note that, at this point, implementation details are not a major concern. Let's not start discarding possibilities just because they \emph{could} be slow or hard to implement.

\chapter{Streams of tuples}
- What can you do with streams?
- Tuples have timestamps
- Tuples are created with ()
- Use the . operator to access tuple fields

\chapter{Core operations}
The core-operations include all the SQL-like constructs that can be used to manipulate data. They are the ``assembly language'' of StreamPy and everything the user can do with StreamPy, he can do so using these core operations.

All the core operations act on streams and return new streams. This is an important point to retain, and one that will make sense by the end of this chapter.

\section{Projections}
A projection allows one to manipulate all the tuples on a stream. For instance, if \emph{stocks} is a stream with tuples of the form \tuple{Tick, Value, Volume} representing stock exchanges, one could obtain only the \emph{Tick} and the \emph{Value} with:
\begin{alltt}
  ticks_and_values = stocks.map \{ |t| (:Tick => t.Tick, :Value => t.Value) \}\footnote{Please note that, at this point, the syntax is not yet set in stone. Actually, it could become something completely different like Python's list comprehensions. I'm more worried with the semantics, not the syntax.}
\end{alltt}
In this example, \verb=map= is the projection operator that applies the code inside brackets to every tuple in the stream. That is, everything inside brackets is actually an anonymous function or lambda expression that receives one argument, namely the tuple \verb=t=. Inside this lambda expression we create a new tuple with two fields --- ``Tick'' and ``Value''. The ``Tick'' of this new tuple will be just the tick from the old tuple and the same holds for the ``Value'' field.

In a Pythonic way, the same example could be expressed as:

\begin{verbatim}
  ticks_and_values = [(:Tick => t.Tick, :Value => t.Value) for t in stocks]
\end{verbatim}

Or in LINQ as:

\begin{verbatim}
  ticksAndValues = stocks.Select(t => new { Tick = t.Tick, Value = t.Value })
\end{verbatim}

The result of the map operation is a stream with the new tuples. Thus, one can perform further operations on it, like multiplying the value by the scalar 2:

\begin{verbatim}
  ticks_and_values.map { |t| (:Tick => t.Tick, :ValueX2 => t.Value * 2) }
\end{verbatim}

\section{Filters}

One can also filter tuples in a stream based on a predicate. The resulting stream will include only those tuples where the predicate returns true. For example, to obtain only the Apple tuples one could do:

\begin{verbatim}
  apple_stocks = input.filter { |t| t.Tick == "AAPL" }
\end{verbatim}

Sometimes the user may want to partition a given stream into two or more streams. For example,

\begin{verbatim}
  apple_stocks = input.filter { |t| t.Tick == "AAPL" }
  msft_stocks = input.filter { |t| t.Tick == "MSFT" }
  google_stocks = input.filter { |t| t.Tick == "GOOG" }
\end{verbatim}

Maybe it's a good idea to create a language construct just to simplify these cases:

\begin{verbatim}
input.partition(:Tick)
    | "AAPL"    >> apple_stocks
    | "MSFT"    >> msft_stocks
    | "GOOG"    >> google_stocks
    | otherwise >> other_stocks
\end{verbatim}


\section{Aggregators}

Aggregators represent a set of functions that are applied to the entire stream and return a single value. Example aggregators include \verb=min()=, \verb=max()=, \verb=sum()= or \verb=average()=. A generic aggregator like Lisp's \verb=reduce= is also included:

\begin{verbatim}
  input.fold(0) { |a, t| a += t.Value * t.Volume }
\end{verbatim}

In this example, \verb=0= is the initial value of the aggregator. \verb=fold= calls the code block inside brackets for every tuple in the stream. This block receives two arguments: \verb=a= is an accumulator that starts with the initial value (0 in this case) and \verb=t= is the tuple. For every tuple, the product of the tuple's \emph{Value} and \emph{Volume} is added to the accumulator. The result of the entire operation is the final value of the accumulator\footnote{How generic is fold? Can you do a simple average with it?}.

As new tuples arrive into the stream, the value of the aggregator changes. Thus, the aggregator itself can be seen as a stream of values. That is, in fact, the case in StreamPy. Treating the value of an aggregator as a normal stream comes with a few advantages as normal stream operations can be applied to this stream. Want to know when was the average of all stocks bigger than a given threshold? Easy. Want to calculate a moving average over the average of Apple stocks for the last few days? Easy\footnote{I wrote this before I knew that Oracle allows you to save historical data. Seemed a bit of a crazy idea before :-)}.

\section{Sorting}

As the name implies, sorting allows the developer to sort the tuples contained in a stream by some field:

\begin{verbatim}
  input.sort(:Value)
\end{verbatim}

It should also be possible to specify the order of the sort (ascending or descending) and sort by multiple fields. Also, more complex sorting operations where the user specifies the comparator should also be allowed.\footnote{Is sorting really necessary? Streams should be ordered by timestamp and any other order seems unnatural.}

\section{``Group by'' and ``having''}

In its simplest form, \emph{group by} creates a new group for each value of a given field and assigns tuples to those groups based on the value of that field. Then, for each group, an aggregator is applied:

\begin{verbatim}
  max_by_tick = input.groupby(:Tick) { |group| group.max(:Value) }
\end{verbatim}

\verb=group= is actually a substream that will contain only the tuples from the original stream with the same ``Tick'' value. Thus, one new substream will be created for each different ``Tick''. These substreams can, of course, be the subject of all stream operations like projections, filters, etc.

The result can then be accessed in a dictionary-like way. For example, to obtain the average of Apple stocks one could do:

\begin{verbatim}
  max_by_tick["AAPL"]
\end{verbatim}

The \emph{group by} operator should also allow partitioning by more than one field at a time and even let the user specify the grouping algorithm. For example, if the user wants to partition the tuples into those whose ticks run from ``A'' to ``G'', ``H'' to ``T'' and ``U'' to ``Z'', he should be able to do so.

Just like other stream operations, \emph{group by} also returns a stream. Thus, the stream \verb=max_by_tick= may be further filtered, projected, aggregated, etc.\footnote{What about windows? Does it make sense to apply a window to a ``group by'' result?}

It's not clear at this point if it is mandatory that an aggregator be applied for each group. The user might want to return more than a simple value. For example, he may want to get the last three tuples per tick:

\begin{alltt}
  max_by_tick = input.groupby(:Tick) \{ |group| group[3] \}\footnote{Windows will be discussed later. For now, you just need two now that group[3] will return the last three tuples in the stream.}
\end{alltt}

Does ``having'' make sense in this case?

\section{Joining multiple streams}
\section{Windows}
\section{The flux operator}
\section{More examples}

\chapter{Recognizing events through pattern matching}
\chapter{More examples}
\end{document}
