\documentclass{report}

\usepackage{framed}
\usepackage{alltt}

\begin{document}
\title{Technical Report}
\author{Lu\'{\i}s Pureza}

\maketitle

\tableofcontents

\addtolength{\parskip}{\baselineskip}

\chapter{Architecture}

My goal is to develop a stand-alone interpreter that receives the name
of an EzQL file in the command-line, as well as some configuration for
the input adapters, and executes the code as events arrive in those
adapters. For example:

\begin{verbatim}
$ ./ezql linear-road.ezql PosSegStr=file://pos-seg-stream.csv
\end{verbatim}

This would execute the linear-road.ezql file, using the file
pos-seg-strem.csv as input to the \verb=PosSegStr= stream. Below we
show some possible contents of this file:

\begin{verbatim}
timestamp, vehicleId, speed, segNo, dir, hwy
        0,        10,    50,     3,   1,   3
      100,         5,    40,     6,   0,   2
      130,         2,    35,     2,   1,   1
\end{verbatim}

Each line (except the first) represents an event that will be fed up
to the \verb=PosSegStr= stream at the given timestamps. In this
example, the first event will be sent to the stream as soon as the
application is ready, the second will follow 100 milliseconds later,
the third 130 milliseconds later and so on.

Naturally, this approach is good for testing and validation, but the
real world doesn't work this way -- we don't know the events
beforehand! One could implement some other kind of input adapter (for
example, one which receives events from some network socket), but this
issue is orthogonal to this internship.

Why a stand-alone interpreter and not an application-server? Well,
because it seems to be the fastest and easiest route to have something
that works. I see no reasons why an application-server that executes
EzQL applications could not be written in the future.

And finally, why an interpreter and not a full-blown compiler? Again,
fastest route. A compiler would take considerable time to write and
test, and if I was to implement one during this internship, the EzQL
language would necessarily have less features. I prefer to prove that
the language can do many things well compared to what's in the state
of the art. Optimization comes later, if this is ever going to be used
in production.

\chapter{Execution model}

EzQL supports two modes of execution: continuous and ``one-shot''. The
first is what we usually call ``continuous queries'', i.e., ``queries
that are issued once and then logically run continuously over the
database (in contrast to traditional one-time queries which are run
once to completion over the current data sets)'' (taken from
``Continuous Queries over Data Streams'', by Babu and Widom).

Take, for instance, the following program:

\begin{verbatim}
stocks = Stream of { :symbol, :price }

@createFrom(stocks, :symbol)
class Company
end

cheap_companies =
  from c in all Company
  where c.price < 10
  select c
\end{verbatim}

\verb=cheap_companies= is a collection that contains -- \emph{at any
  moment} --, the companies whose stocks are worth less than \$10. The
query that generates this collection is \emph{active} while the
program is running. As soon as a new price report is received, the
query will be executed and the corresponding company object may be
added or removed from \verb=cheap_companies=. This is completely
transparent to the developer, because he doesn't need to specify when
this computation should take place. The engine takes care of the
details. All the developer needs to know is that the contents of that
collection are always consistent with what the user expects them to
be. In a way, I would consider this an abstraction.

There are situations when one wants to execute some action in a
one-shot way. These actions could be scheduled in advance -- ``Print
the symbols of all the cheap\_companies at 11:00 am'' --, or could
happen in response to some event -- ``when the car moves to a new
segment, calculate the new toll for that segment''. In my opinion,
these actions are mostly useful for their side-effects and continuous
queries are not appropriate to handle them. The following query, taken
from the linear road benchmark solution in CQL, shows this:


\begin{verbatim}
Select Rstream(E.vehicleId,
               basetoll * (V.numVehicles - 150)
                        * (V.numVehicles - 150) as toll)
From VehicleSegEntryStr [Now] as E,
     CongestedSegRel as C, SegVolRel as V
Where E.segNo = C.segNo and C.segNo = V.segNo and
      E.dir = C.dir and C.dir = V.dir and
      E.hwy = C.hwy and C.hwy = V.hwy
\end{verbatim}

According to the semantics of CQL, this query is executed when a
vehicle switches segments (an event that goes into
\verb=VehicleSegEntryStr[Now]=). But what happens when a previously
congested segment stops being congested? Or when the number of
vehicles in a segment changes? Well, as long as no vehicles switch
segments, the join condition will fail and nothing will be produced. I
find it hard to reason about the runtime behavior of programs this
way. It gets more complicated when we join several windows
together. Should a new result be produced every time one of the
windows change? Is this what the user wants? I'd rather have the
option to express these actions using something along the lines of:

\begin{verbatim}
when <vehicle v switches to segment s>
    s.updateToll()

...

class Segment
    ...

    def updateToll()
        if this.isCongested then
            this.toll = basetoll * (this.vehicles.length - 150) ^ 2
    end

\end{verbatim}

This snippet should be easily understandable, except maybe how to
determine that a segment is congested, and how to find out the
\verb=Segment= object corresponding to the segment the vehicle just
entered. I'll ignore these details for now.

The important thing to retain is that everything inside the
\verb=when= (including the call to the \verb=updateToll()= method) is
executed sequentially, just like a Java or Python program.

Naturally, \verb=toll= is an attribute of any segment that may be used
in queries:

\begin{verbatim}
cheap_tolls =
  from s in all Segment
  where s.toll < 10
  select s
\end{verbatim}

One thing I haven't decided yet is if we should allow queries inside
pieces of code that are going to be executed sequentially. For
example:

\begin{verbatim}
when <vehicle v switches to segment s1>
    <calculate and print the average speed in that segment over
     the last 5 minutes>
\end{verbatim}

This is a one-time query that runs until completion every time a
vehicle switches to a specific segment. As it is not a continuous
query, the system must be aware that it needs to save the last 5
minutes of data for that segment. What about the other segments?
Should it keep their data too, or is it smart enough to figure out, by
looking at the code, that only segment s1 will be necessary?

\chapter{Language paradigm}
The way I see it, you have:

\begin{itemize}
\item Classes (with fields and methods) to model entities;
\item Function definitions;
\item Continuous queries;
\item when blocks for sequential programming
\end{itemize}

\section{Classes}

\begin{itemize}
\item Should we allow user defined classes for things besides
  entities? What about inheritance, polymorphism...?
\end{itemize}

\section{Functions}

Functions are just like regular functions from other programming
languages, with a few rules. First, you cannot call a function from
the top-level (i.e., \verb=main()= in Java). Actually, there doesn't
even exist a top-level in EzQL. To see why, consider the following
code:

\begin{verbatim}
def f()
    print "Hello world"
end

class Segment
end

f()   # <<<<<<<<<<<<<<<<<<<<<<

cheap_tolls =
  from s in all Segment
  where s.toll < 10
  select s
\end{verbatim}

When should \verb=f= be called? During start-up? Every time an event
arrives? The former makes some sense, but we may as well create some
kind of ``initialization area'' and stick it there:

\begin{verbatim}
when Initializing # Initializing is a dummy event
    f()
\end{verbatim}

This may seem a \verb=main()= method in disguise. Note, however, that
when \verb=f= returns and the \verb=when= block terminates, the
program remains in execution.

You may call functions from anywhere inside a \verb=when= block, or
from other functions. This is just like regular sequential programming
and should be clear.

You may also call functions from specific points in continuous
queries, in particular, inside \verb=where= filters and \verb=select=
statements:

\begin{verbatim}
def lessThan(value, threshold)
    value < threshold
end

def log(value)
    ...
end

cheap_tolls =
  from s in all Segment
  where lessThan(s.toll, 10)
  select log(s.toll)
\end{verbatim}

I would also like to allow the user to implement his own aggregates
and even operators (i.e., his own \verb=where=, \verb=select=, etc)
because there's no way the standard ones will be enough. This is very
low priority stuff though and would require much more time than I
possess (besides, it is difficult to convince people that the standard
operators are not enough).

\chapter{Data types}

The difficult question. So, you have:

\begin{itemize}
\item Primitive types
  \begin{itemize}
  \item ints, floats, strings, \ldots;
  \item Continuous values: they are just regular ints or floats or
    strings or whatever, that are used in continuous queries and thus,
    are always defined. We may also create windows on these values to
    analyze their past values;
  \item Functions: In EzQL functions may be called, passed to other
    functions as arguments, a function may return another function,
    etc;
  \end{itemize}
\item Compound types:
  \begin{itemize}
  \item Objects;
  \item Events: I see events as objects. You can pass events to
    functions, create new events and access specific attributes of
    events (\verb=temp_reading.room_id=);
  \end{itemize}
\item Collections:
  \begin{itemize}
  \item Streams;
  \item Windows (temporal or fixed-size);
  \item Windows on continuous values (for instance,
    \verb=price[5 min]=);
  \item Dictionaries: the result of all \verb=from ... in all ...=
    queries is a dictionary (or hash-table). You may index specific
    objects using, for instance, \verb=cheap_companies["ACME"]=. The
    result of a \verb=group by= is also a dictionary.
  \end{itemize}
\end{itemize}

Should we allow other types for sequential programming? Lists,
hash-tables, trees, bags, sets, heaps...?

TODO: Allowed operations between data types

\chapter{Abstractions}

\end{document}
