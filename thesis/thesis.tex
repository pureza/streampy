\documentclass{report}


\usepackage{alltt}

\begin{document}
\title{StreamPy: A new language for Event Stream Processing}
\author{Lu\'{\i}s Pureza}

\maketitle

\tableofcontents

\addtolength{\parskip}{\baselineskip}
\chapter{Introduction}

Technology developments and its widespread adoption over the last decades have significantly increased the demand for information processing systems. Not only do we now need to process larger amounts of information traveling around the globe, we must do it faster as well. For some companies, obtaining results a few milliseconds earlier may be a significant advantage over the competition. For others, however, reacting immediately is of critical importance, as it happens, for example, in the case of security breaches or nuclear power plant malfunctions.

One particular class of applications, now referred to as Event Stream Processing (ESP) systems, has been the subject of much attention over the last few years due to the technical challenges it presents. ESP systems are characterized by dealing with a possible infinite amount of data constantly flowing in to be processed as fast as possible to continuously produce new and updated results that may themselves be used as knowledge to justify new decisions. As it happens, many applications fit naturally in this model: financial analysis, health-care monitoring, network intrusion detection, personnel and product tracking through RFID devices, business monitoring and many more.

Due to the inability of current technology to satisfy the increasing demands from all these markets, computer scientists developed the first Data Stream Management Systems (DSMS). Coming mostly from the database community, these researchers intended to build a generic engine that abstracted away all the low level details of managing streams of data in high demanding scenarios, while retaining much of the querying capabilities of regular DBMSs, so that they could be easily adapted to a multitude of domains. It's no surprise then, that the first DSMSs inherited a SQL dialect with some new extensions. Aurora, with its boxes and arrows graphical queries was the exception, but the operators it provided still took inspiration from SQL. Later, when the first DSMS hit the market, some emphasis was put on end-user interaction and some systems began to support trigger-like rules that executed programmed actions when some conditions became true. At the same time, DSMS began to incorporate features from Complex Event Processing (CEP) systems, that allowed the user to detect complex patterns and correlations among the input streams of data. This required adding new constructs into the query language. Recently, some companies unhappy with declarative, SQL-like languages, began to support procedural languages, more familiar to C and Java programmers. Nowadays, each product includes its own flavor of a SQL-like language with its own unique and esoteric extensions, or a rule-based language, or a procedural language, or any combination of these three. And all have different semantics which disagree in fundamental ways. Besides the obvious issue created by the lack of a standard, all this variety demonstrates that DSMS applications have their own needs and a satisfactory end-user query language for them is yet to be found.

The purpose of this internship is to design a new query language for ESP systems. This new language combines powerful constructs, with some innovative features that, we hope, should be a step in the right direction to create a language that developers find rich, expressible and coherent. The rest of this thesis is organized as follows:

\begin{itemize}
\item In chapter \ref{state-of-the-art}, we will expand on the previous paragraph to detail the state-of-the-art and to show that art is indeed very subjective;
\item The goal of chapter \ref{problem-statement} is to show, through real-world examples, that even though some common queries are easily expressible in currently available systems, they all fail to scale when it comes to slightly more complex -- yet perfectly reasonable, scenarios. We will conclude this chapter by analyzing why all these systems fail and what fundamental constructs they're lacking;
\item Our proposal will then be introduced in chapter \ref{streampy}, first through the analysis of a few examples followed by a thorough discussion of all its features;
\item Further work and planning for the next semester will be the topic of chapter \ref{future-work};
\item Finally, chapter \ref{conclusion} concludes this document.
\end{itemize}

By the end of this document, it should be clear that not only current technology will fail short of fulfilling the increasing needs of costumers, but also that our proposal contains some interesting characteristics that deserve further attention.

\chapter{State-of-the-art}\label{state-of-the-art}

This section will analyze query languages present in all major DSMSs - Coral8, StreamBase, Oracle CEP, Progress Apama and Aleri. Esper, an open-source engine will also be mentioned. Most, if not all, of these products are marketed as CEP engines but they're in fact DSMSs that include some CEP features pioneered by Stanford's Rapide project, which will also be discussed. Then, two alternative methods of creating queries visually, one through a boxes and arrows interface and the other through spreadsheet manipulation will also be discussed. Despite not involving programming languages, it's important to study these methods because, after all, they're trying to address the same problem. Finally, two languages that inspired this work. First comes LINQ -- a query language that integrates with .NET and brings the expressivity of SQL to procedural languages like C\#. Second, Yahoo's Pig, a language designed to create map-reduce jobs whose procedural nature makes it popular among developers.

\section{SQL-based languages from Coral8, StreamBase and Esper}

The most popular way of writing queries is through a declarative, SQL-based language. As explained in the introduction, this comes as a result of all the effort the database community has put into creating the first ESP engines. Currently there is no standard for a query language designed specifically for these applications which means each vendor has their own. Fortunately, they're all very similar. The simplest things can be done exactly as in regular SQL:

\begin{verbatim}
INSERT INTO PriceMicrosoft
SELECT *
FROM StockTrades
WHERE symbol = 'MSFT'
\end{verbatim}

This query looks for tuples where the field \verb=symbol= equals ``MSFT'' arriving at the stream \verb=StockTrades= and adds them to the \verb=PriceMicrosoft= stream. It's just a simple filter.

One feature that assumes particular importance in the context of ESP is the concept of window. Similar to SQL OLAP windows, ESP windows allow developers to consider only part of a stream and make computations over it. In particular, it becomes possible, for example, to calculate the most expensive order among the last million, or the average of Microsoft's stock prices over the last 3 hours, as the following example shows:

\begin{verbatim}
INSERT INTO AvgPriceMicrosoft
SELECT avg(price)
FROM StockTrades KEEP 3 HOURS
WHERE symbol = 'MSFT'
\end{verbatim}

It's possible to customize the retain policy and keep, for example, the 10 largest updates based on their price, the 10 last updates per company or simply to keep everything.

The window defined in the previous example is a \emph{sliding} window. Sliding, in this context, refers to how and when the elements in the window expire. In these kinds of windows, tuples are removed from the window as they become too old or new tuples arrive. An alternative is \emph{jumping} windows, where tuples are appended to the window and then, when the oldest element was supposed to be removed, all of them expire at the same time, the window becomes empty and the cycle begins all over again. This way, it's possible to find out the largest price attained by Microsoft stocks over the last hour, the hour before and so on.

All the examples in this section were written in Coral8 Continuous Computation Language (CCL). Nonetheless, all the other systems in this section provide similar features albeit with different syntax. In fact, there've been talks about creating a standard language lately, an ideia that was met with some skepticism by some vendors and users that don't like SQL anyway and opted for other approaches.

SQL based solutions come with a few problems, however. First, experience tells that SQL queries easily become overly complex and hard to understand. Second, SQL's declarative nature doesn't always map well with the way programmers think. Sometimes, things that are simple to do in C or Java become ugly hacks when translated to SQL, because SQL, despite being Turing complete, just wasn't made to compete with those languages. In chapter \ref{problem-statement} we will develop these arguments and show that DSMS systems need a better option.

\begin{verbatim}
CurrentPrice: 
    Select    P.itemID, Max(P.price) as price
    From      ((Select itemID, bid_price as price 
                From   Bid) Union All
               (Select itemID, start_price as price 
                From OpenAuction)) P
    Group By  P.itemID

ClosingPriceStream:
    Select   Rstream(T.id as catID, P.price as price)
    From     ClosedAuction [Now] C, CurrentPrice P, 
             Item I, Category T    
    Where    C.itemID = P.itemID and C.itemID = I.id and I.categoryID = T.id 
\end{verbatim}

What's wrong with these queries? First of all, notice that besides the \verb=ClosingPriceStream= -- the desired result, two other temporary streams had to be created. Sure, they are not strictly necessary and their code could be direcly inserted in the \verb=FROM= clause of the \verb=ClosingPriceStream=, but that wouldn't be a wise choice, would it? To avoid creating big and complex queries, developers partitionate them into smaller ones that write their results to temporary streams that are then used by other queries. Thus, streams end up being used as variables, to store the intermediate results of computations. But streams aren't a suitable replacement for all kinds of variables in a procedural programming language. There, programmers can choose among primitive variables (int, float, string, \dots), arrays, dictionaries, lists and sets among others, to manage information. And let's not forget about classes and objects, fundamental not only to keep information in an organized way, but also because the way they let developers think in terms of the real world and model objects and the relations between them. Certainly, streams and tables alone could be used to simulate all these kinds of constructs, but they're just not the right tool for \emph{every} job.

Second, notice the query for the \verb=CurrentPrice= stream. To find the current price, it first finds the starting price, then all the prices from later bids and finally it chooses the largest, which is also the latest. Notice how the query builds, implicitly, the current state of each product. This is necessary because the DSMS doesn't know what a product really is. All it sees are tuples arriving. In between events, it's like a product doesn't have a price -- that's why it is necessary to tell it to go back and get the price from the latest event. Wouldn't it be nicer to have \verb=Product= objects with properties like \verb=current_price= to hold the state of the product, just like in an OOP language? Furthermore, wouldn't it be nicer if the system knew how to automatically modify these properties as new events arrived? And finally, wouldn't it be nicer if those instances could, themselves, be used in queries just like regular tuples?

Third, notice the \verb=WHERE= predicate in the last query. What could possibly be wrong with it? It's just a harmless join! The problem is, this join hides an important fact about the system being modelled: objects have relations! Actions have one product and products have zero or more bids. Relations are not new to the database community: DBMSs have embraced and supported them for years. But database relations are still considered too low-level by most programmers, who are used to think in terms of objects instead of meaningless identifiers. This is one reason why Object-Relational Mapping (O/RM) has flourished in the last few years. Again, wouldn't it be nicer if the developer could, somehow, instruct the system about these relations and then the objects mentioned in the previous paragraph would be enriched with pointers to the related objects, all of this managed by the system behind the scenes?

\section{Building queries visually with StreamBase's EventFlow}

StreamBase employs an alternative, more user-friendly, way of building queries. Instead of writing code, the user can design queries visually, by arranging boxes in a canvas and connecting them with arrows. Boxes represent operators that receive data coming from other operators or directly from the input streams, process the data according to its semantics and send the results to be handled by other operators, or to the world as the output of the whole operation.

\emph{TODO Show picture}

Some of the most important operators are:

\begin{description}
\item [Aggregate] Computes aggregate operations over windows of tuples. Supports the option to partition tuples into sets and then apply the aggregation over each individual set, much like a SQL GROUP BY statement;
\item [Filter] Discards some tuples from the input stream based on a predicate. Performs the same function as a SQL WHERE statement;
\item [Gather] Receives tuples from two or more streams and concatenates those with the same key. The resulting tuple values may be direct copies from the original tuples or the result of applying some expression to these;
\item [Join] Similar to SQL joins, this operator pairs tuples coming from two streams that match a given condition and outputs a new tuple whose fields may be specified by the user. In general, joining two infinite streams may require keeping all tuples from both streams in memory. To avoid problems later on, the user must specify timing constraints regarding matching tuples saying, for example, that they must arrive withing 60 seconds of each other;
\item [Map] Similar to the first part of a SELECT statement, this operator transforms a tuple -- possibly discarding or adding new fields along the way, and sends it downstream;
\item [Pattern] Instructs the engine to look for complex events. This is a feature borrowed from Complex Event Processing and will be discussed below;
\item [Union] Acts as a multiplexer, connecting many input streams to a single output stream, to where all tuples are sent. Similar to the SQL UNION statement.
\end{description}

It's clear that most of these operators have SQL conterparts. StreamBase acknowledges this and provides a small utility to convert EventFlow diagrams to StreamSQL queries, thus proving that everything that can be done with the former can be done with the later. Or almost everything. In fact, this converter has a few limitations outlined in [ref], but these don't really harm the veracity of the previous statement. It's then mostly a matter of taste -- not power, to choose between StreamSQL and EventFlow.

\section{Oracle rules}

Oracle Rules Manager (ORM) embraces a completely different paradigm. Instead of writing queries, the user creates rules that are made of three parts. The first -- the event type, instructs the system to trigger the rule only when an event of that type occurs. The second, the condition, is a predicate that is compared against the event. If they match, the third part, the action, is executed.

Conceptually, a rule has the following format:

\begin{verbatim}
ON   <event>
IF   <condition>
THEN <action>
\end{verbatim}

The following example shows a simple rule:

\begin{verbatim}
ON   StockTick(symbol, price, volume)
IF   symbol = 'MSFT' and price > 100
THEN buyStocks(symbol)
\end{verbatim}

The event shown above represents a stock update received from some external source. These are the simplest kind of events, also called \emph{primitive} events. ORM also supports \emph{composite} events that are defined as combinations of other events. For example, it is possible to define a composite event that occurs when Microsoft shares drop by 10\% and, less than 5 minutes later, IBM shares gain 2\%. To be more specific, the following types of combinations are supported:
\begin{description}
\item [Sequencing] Specifies the order between events, i.e., event A must occur before event B;
\item [Negation] Checks for the non-occurence of some event. Useful to raise exceptions when business rules are violated;
\item [Set semantics] Allows combining events with the AND operator to specify that all of them must occur for the composite event to occur as well;
\item [Any N] Checks for the occurence of at least N children events;
\item [Collection] Combines a set of primitive events based on some common properties. Could be used, for example, to detect all costumers who withdrew more than \$1000 from their bank accounts during the past 24h.
\end{description}

ORM comes with a GUI utility to simplify the rules creation process. This is necessary because creating a rule the hard way is a daunting task that involves writing SQL queries containing XML blocks containing SQL snippets inside. Still, there are situations when one needs to avoid these utilities and work with real code, situations where a simpler configuration process would be desirable.

How does the rules-based paradigm fares against other alternatives? In our opinion, it all comes down to how well does it map to the real-world scenarious being modelled and how hard it is for the user to wrap his brain around this new way of doing things. This will be the topic of section [ref] where we will provide some concrete examples and analyze their resolution using a rules-based language.

\section{Apama's MonitorScript}

When ESP solutions left the academia to meet the real world, many users argued that SQL was ill-suited for many information processing tasks. MonitorScript (MS) is Apama's response to these complains.

Deriving from the procedural family of programming languages, MS programs look a lot like Java programs. However, the most important and unique feature it includes was borrowed from Erlang: the process model based on having many little \emph{processes} that execute in parallel and communicate with each other through messages. In MS, these entities are called \emph{monitors}. A monitor is an event processing agent that basically sets up an arbitrary number of \emph{listeners} that await for the occurence of events. When one matching event arrives, monitors processes it. Monitors can also send events to each other, through the \emph{route} statement.

Last but not least, monitors can have state. This means that instead of writing a SQL query to capture the state of the system, MS updates the state incrementally as the computation moves forward. The downside is that, for simple things, SQL queries will definitely be easier to understand, because a SQL query \emph{is} its intention while, in a procedural program, the big picture is not always that clear.

\emph{TODO show and discuss sample program}

MS and SQL are at opposite ends of the programming language spectrum. While is simplifies a lot of tasks that don't naturally fit into SQL, MS also looses all the querying capabilities that made SQL and its derivatives popular for data processing. Wouldn't it be nicer to combine these two languages, much like Microsoft has done with LINQ?

\section{The Rapide way: event hierarchies}

\section{Microsoft's LINQ}

\chapter{Problem statement}\label{problem-statement}

Talk about:
\begin{itemize}
\item The declarative nature of SQL queries can be very expressive for simple things, but remain totally opaque for more complex scenarios;
\item So, complex queries must be partitioned into smaller ones. To connect these new queries, temporary streams are created. But streams are not suitable replacements for ALL of the following: structures/classes, dictionaries, sets, linked lists or even arrays!
\item In many scenarios, we use SQL to rebuild the state of the system. Wouldn't it be nicer to maintain the state explicitly and update it incrementally, just like in procedural programming languages?
\item SQL queries don't compose;
\item If we've been building Java applications to process data while demoting SQL as just a way to obtain it for ages, why resorting now to a SQL-only solution?
\end{itemize}

\chapter{The StreamPy query language}\label{streampy}

\chapter{Future work}\label{future-work}

\chapter{Conclusion}\label{conclusion}
\end{document}
